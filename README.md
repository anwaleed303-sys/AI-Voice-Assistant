# AI Voice Assistant

A modern, AI-powered voice assistant built with Next.js, TypeScript, and Ant Design. Features seamless voice interactions, multilingual support, and integration with Groq's powerful LLM models.

## ğŸš€ Features

- **Voice Command Support**: Natural speech recognition using Web Speech API
- **Multilingual Capabilities**: Support for 13+ languages
- **AI-Powered Responses**: Integration with Groq API and Llama models
- **Responsive Design**: Optimized for all devices (mobile, tablet, desktop)
- **Real-time Transcription**: Live voice-to-text conversion
- **Text-to-Speech**: Browser-based speech synthesis
- **Modern UI**: Beautiful interface with Ant Design components
- **Serverless Architecture**: Vercel-ready API routes

## ğŸ“‹ Prerequisites

- Node.js 18+
- npm or yarn
- Groq API key (get it from [console.groq.com](https://console.groq.com))

## ğŸ› ï¸ Installation

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/ai-voice-assistant.git
cd ai-voice-assistant
```

2. **Install dependencies**

```bash
npm install
# or
yarn install
```

3. **Set up environment variables**

```bash
cp .env.example .env.local
```

Edit `.env.local` and add your Groq API key:

```
GROQ_API_KEY=your_groq_api_key_here
```

4. **Run the development server**

```bash
npm run dev
# or
yarn dev
```

5. **Open your browser**
   Navigate to [http://localhost:3000](http://localhost:3000)

## ğŸŒ Deployment on Vercel

1. **Install Vercel CLI** (optional)

```bash
npm i -g vercel
```

2. **Deploy using Vercel CLI**

```bash
vercel
```

Or deploy via GitHub:

1. Push your code to GitHub
2. Import project in Vercel dashboard
3. Add `GROQ_API_KEY` environment variable
4. Deploy!

## ğŸ“ Project Structure

```
ai-voice-assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/              # Vercel serverless functions
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/         # Chat completion endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ speech-to-text/ # Speech recognition endpoint
â”‚   â”‚   â”‚   â””â”€â”€ text-to-speech/ # Text-to-speech endpoint
â”‚   â”‚   â”œâ”€â”€ layout.tsx        # Root layout
â”‚   â”‚   â”œâ”€â”€ page.tsx          # Home page
â”‚   â”‚   â””â”€â”€ globals.css       # Global styles
â”‚   â”œâ”€â”€ components/           # React components
â”‚   â”‚   â”œâ”€â”€ VoiceAssistant/   # Main voice assistant component
â”‚   â”‚   â”œâ”€â”€ LanguageSelector/ # Language selection
â”‚   â”‚   â””â”€â”€ ModelSelector/    # AI model selection
â”‚   â”œâ”€â”€ hooks/               # Custom React hooks
â”‚   â”œâ”€â”€ lib/                 # Utility functions
â”‚   â””â”€â”€ types/               # TypeScript type definitions
â”œâ”€â”€ public/                  # Static assets
â”œâ”€â”€ .env.example            # Environment variables template
â”œâ”€â”€ next.config.js          # Next.js configuration
â”œâ”€â”€ package.json            # Dependencies
â””â”€â”€ tsconfig.json           # TypeScript configuration
```

## ğŸ”‘ API Routes

### POST /api/chat

Chat completion with AI models

```typescript
Request: {
  messages: Array<{ role: string; content: string }>;
  model: string;
  language?: string;
}

Response: {
  message: string;
  model: string;
  usage?: { ... };
}
```

### POST /api/speech-to-text

Convert speech to text (uses Groq Whisper)

```typescript
Request: {
  audio: string; // base64 encoded
  language?: string;
}

Response: {
  text: string;
  language: string;
}
```

### POST /api/text-to-speech

Convert text to speech

```typescript
Request: {
  text: string;
  language?: string;
}

Response: {
  useClientTTS: boolean;
  // Uses browser Web Speech API
}
```

## ğŸ¨ Customization

### Adding New Languages

Edit `src/lib/constants.ts`:

```typescript
export const SUPPORTED_LANGUAGES: Language[] = [
  { code: "en-US", name: "English (US)", flag: "ğŸ‡ºğŸ‡¸" },
  // Add your language here
];
```

### Adding New Models

Edit `src/lib/constants.ts`:

```typescript
export const GROQ_MODELS: GroqModel[] = [
  {
    id: "model-id",
    name: "Model Name",
    description: "Model description",
  },
];
```

## ğŸ”§ Technologies Used

- **Framework**: Next.js 14 with App Router
- **Language**: TypeScript
- **UI Library**: Ant Design
- **Styling**: Tailwind CSS
- **AI Integration**: Groq SDK
- **Voice Recognition**: Web Speech API
- **Deployment**: Vercel Serverless Functions

## ğŸ“ Available Models

- **Llama 3.3 70B Versatile**: Most capable model
- **Llama 3.1 70B Versatile**: Previous generation
- **Llama 3.1 8B Instant**: Fast responses
- **Mixtral 8x7B**: Large context window
- **Gemma 2 9B**: Instruction-tuned

## ğŸŒ Supported Languages

English, Spanish, French, German, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, Hindi, Urdu, and more!

## ğŸ› Troubleshooting

**Voice recognition not working?**

- Use Chrome, Edge, or Safari (Firefox doesn't support Web Speech API)
- Grant microphone permissions
- Use HTTPS (required for microphone access)

**API errors?**

- Verify your Groq API key in `.env.local`
- Check API rate limits
- Ensure you have internet connection

## ğŸ“„ License

MIT License - feel free to use this project for personal or commercial purposes.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“§ Support

For issues or questions, please open an issue on GitHub.

---

Built with â¤ï¸ using Next.js and Groq AI
